{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test des modèles sur des images de Google Street"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Ce notebook contient un bout de code permettant d'evaluer nos différents modèles entrainés sur des images tirés automatiquement de Google Street, afin de vérifier si ls modèles ont très bien généralisé leur apprentissage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation des modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "def check_path_exists(Path,Message):\n",
    "    if not os.path.exists(Path):\n",
    "        print(Message)\n",
    "        sys.exit(1)\n",
    "# Cette partie permet d'ajouter le dossier parent au path, pour pouvoir importer les modules que nous avons créés. ça peut être soit un chemin\n",
    "# absolu, soit un chemin relatif. Ici, c'est un chemin absolu (à changer pour votre cas)\n",
    "Path_Modules = \"/home/ayoubchoukri/Etudes/5A/Stats_Grande_Dimension/Projets/Projet/Projet_HDDL_2/Commun/Commun_Ayoub/Modules\"\n",
    "Path_Models = \"/home/ayoubchoukri/Etudes/5A/Stats_Grande_Dimension/Projets/Projet/Projet_HDDL_2/Commun/Commun_Ayoub/Models\"\n",
    "check_path_exists(Path_Modules,\"Le chemin spécifié pour importer les modules n'existe pas. Il faut surement le modifier.\")\n",
    "\n",
    "\n",
    "sys.path.append(Path_Modules)\n",
    "sys.path.append(Path_Models)\n",
    "\n",
    "# Importer les module\n",
    "from Preprocessing import *\n",
    "from Resnet import *\n",
    "from Test import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation des images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "folder_test_images_path = \"/home/ayoubchoukri/Etudes/5A/Stats_Grande_Dimension/Projets/Projet/Projet_HDDL_2/Commun/Donnees_Test\"\n",
    "\n",
    "# Checker si le dossier existe\n",
    "check_path_exists(folder_test_images_path,\"Le chemin spécifié pour les images n'existe pas. Il faut surement le modifier.\")\n",
    "\n",
    "\n",
    "# Renommer les images\n",
    "RENAME = True\n",
    "\n",
    "if RENAME : \n",
    "    rename_images_in_folder(folder_test_images_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize=True\n",
    "size=(224,224)\n",
    "normalize=True\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "Images_Original,Images = import_images_nparrays_test(folder_test_images_path, resize=True, size=(224,224), normalize=True)\n",
    "\n",
    "Images = torch.tensor(Images, dtype=torch.float32)\n",
    "\n",
    "Images = Images.to(device)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affichage des images pour visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher les images\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# Plot the first image\n",
    "nb = np.random.randint(0,Images.shape[0],1)[0]\n",
    "Image_To_Plot = Images_Original[nb]\n",
    "\n",
    "Image_To_Plot= np.transpose(Image_To_Plot, (0, 1, 2))\n",
    "plt.imshow(Image_To_Plot)\n",
    "plt.title(f\"Image {nb}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation des modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici on définit un dictionnaire qui va contenir les paths des différents modèles de prédictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model_type_path = \"/home/ayoubchoukri/Etudes/5A/Stats_Grande_Dimension/Projets/Projet/Projet_HDDL_2/Commun/Commun_Ayoub/Saved_Models/Model_Types.pth\"\n",
    "\n",
    "model_Dangers_path = \"/home/ayoubchoukri/Etudes/5A/Stats_Grande_Dimension/Projets/Projet/Projet_HDDL_2/Commun/Commun_Ayoub/Saved_Models/Model_Dangers.pth\"\n",
    "\n",
    "model_Fin_Interdictions_path = \"/home/ayoubchoukri/Etudes/5A/Stats_Grande_Dimension/Projets/Projet/Projet_HDDL_2/Commun/Commun_Ayoub/Saved_Models/Model_Fin_Interdictions.pth\"\n",
    "\n",
    "model_Obligations_path = \"/home/ayoubchoukri/Etudes/5A/Stats_Grande_Dimension/Projets/Projet/Projet_HDDL_2/Commun/Commun_Ayoub/Saved_Models/Model_Obligations.pth\"\n",
    "\n",
    "model_Indications_path = \"/home/ayoubchoukri/Etudes/5A/Stats_Grande_Dimension/Projets/Projet/Projet_HDDL_2/Commun/Commun_Ayoub/Saved_Models/Model_Indications.pth\"\n",
    "\n",
    "model_Interdictions_path = \"/home/ayoubchoukri/Etudes/5A/Stats_Grande_Dimension/Projets/Projet/Projet_HDDL_2/Commun/Commun_Ayoub/Saved_Models/Model_Interdictions.pth\"\n",
    "\n",
    "\n",
    "# Gather models in Dict\n",
    "\n",
    "models_paths = {\n",
    "    \"Types\": model_type_path,\n",
    "    \"Dangers\": model_Dangers_path,\n",
    "    \"Fin_Interdictions\": model_Fin_Interdictions_path,\n",
    "    \"Obligations\": model_Obligations_path,\n",
    "    \"Indications\": model_Indications_path,\n",
    "    \"Interdictions\": model_Interdictions_path\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On définit ici le path des différents dictionnaires d'encodages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_paths = \"/home/ayoubchoukri/Etudes/5A/Stats_Grande_Dimension/Projets/Projet/Projet_HDDL_2/Commun/Commun_Ayoub/Encoding_Dictionaries/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test sur les images de street view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nb_Images_To_Test = 10\n",
    "test_images(Nb_Images_To_Test,Images,models_paths,dict_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse de la robustesse de nos modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin d'analyser la robustesse de nos modèles, on va essayer d'appliquer des transformations basiques sur nos images et voir si la prédiction va changer ou pas, permettant ainsi de voir si nos modèles sont robustes ou pas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Définitions des transformations qu'on va appliquer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.transforms.v2 import *\n",
    "from torchvision import transforms, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "List_Transforms = [\n",
    "        RandomHorizontalFlip(0),\n",
    "        RandomVerticalFlip(0.7),\n",
    "        RandomRotation(25),\n",
    "        # RandomPerspective(),\n",
    "        ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
    "        RandomAffine(degrees=10),\n",
    "        GaussianBlur(5),\n",
    "        transforms.Lambda(lambda img: img + torch.randn_like(img)*0.05),\n",
    "    ] \n",
    "    \n",
    "Transforms = Compose([\n",
    "        RandomApply(List_Transforms, p=1),\n",
    "        ToTensor()\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Transform_Image(Image,Transforms):\n",
    "    Image_To_Transform =  torch.tensor(torch.permute(Image,(2, 0, 1)))\n",
    "\n",
    "    Image_Transformed = Transforms(Image_To_Transform)\n",
    "\n",
    "\n",
    "    return Image, Image_Transformed\n",
    "\n",
    "\n",
    "def Plot_Image_And_Image_Transformed(Image,Image_Transformed,title_left=\"Image Original\",title_right=\"Image Transformée\"):\n",
    "\n",
    "    fig,axes = plt.subplots(1,2,figsize=(20,6))\n",
    "\n",
    "    axes[0].imshow(Image.cpu().numpy())\n",
    "\n",
    "    axes[0].set_title(title_left)\n",
    "\n",
    "\n",
    "\n",
    "    Image_Transformed = torch.permute(Image_Transformed,(1,2,0))\n",
    "    axes[1].imshow(Image_Transformed.cpu().numpy())\n",
    "\n",
    "    axes[1].set_title(title_right)\n",
    "\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the first image\n",
    "nb = np.random.randint(0,Images.shape[0],1)[0]\n",
    "Image = Images[nb]\n",
    "\n",
    "\n",
    "Image , Image_Transformed = Transform_Image(Image,Transforms)\n",
    "\n",
    "Plot_Image_And_Image_Transformed(Image,Image_Transformed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_images_transformed(nbimages,images,folder_models_path,dict_paths,transforms):\n",
    "\n",
    "    for i in range(nbimages):\n",
    "\n",
    "        Image = random.choice(images)\n",
    "\n",
    "\n",
    "        type_pannel,label = test_image(Image,folder_models_path,dict_paths)\n",
    "\n",
    "        Image,Image_Transformed = Transform_Image(Image,Transforms)\n",
    "        # Image = torch.tensor(Image).to(device=device)\n",
    "        # Image_Transformed = torch.tensor(Image_Transformed).to(device=device)\n",
    "\n",
    "        Image_Transformed=Image_Transformed.permute(1,2,0)\n",
    "        type_pannel_transformed,label_transformed = test_image(Image_Transformed,folder_models_path,dict_paths)\n",
    "        Image_Transformed=Image_Transformed.permute(2,0,1)\n",
    "        Title_Left= f'Type pannel: {type_pannel} - Label: {label}'\n",
    "        Title_Right = f'Type pannel: {type_pannel_transformed} - Label: {label_transformed}'\n",
    "        Plot_Image_And_Image_Transformed(Image,Image_Transformed,title_left=Title_Left,title_right=Title_Right)\n",
    "\n",
    "    return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images_transformed(1,Images,models_paths,dict_paths,transforms=Transforms)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Personal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
