{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "from PIL import Image\n",
    "import requests\n",
    "import os\n",
    "import time\n",
    "from io import BytesIO\n",
    "from selenium import webdriver\n",
    "\n",
    "def setup_driver(allow_popups=False):\n",
    "    # Créer une instance de ChromeOptions\n",
    "    chrome_options = Options()\n",
    "\n",
    "    if not allow_popups:\n",
    "        # Désactiver les notifications et pop-ups\n",
    "        chrome_options.add_argument(\"--disable-notifications\")\n",
    "        chrome_options.add_argument(\"--disable-popup-blocking\")\n",
    "        chrome_options.add_argument(\"--disable-infobars\")\n",
    "        chrome_options.add_argument(\"--disable-extensions\")\n",
    "        chrome_options.add_argument(\"--disable-gpu\")\n",
    "\n",
    "        # Désactiver les cookies pour éviter les pop-ups liées aux cookies\n",
    "        chrome_prefs = {\"profile.default_content_setting_values.cookies\": 2}\n",
    "        chrome_options.add_experimental_option(\"prefs\", chrome_prefs)\n",
    "\n",
    "    # Lancer le navigateur avec ces options\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    return driver\n",
    "\n",
    "def scrape_images_with_selenium(queries, num_images=50, folder_name=\"images\", keywords=[\"stop\"], mandatory_keywords={}, allow_popups=False, saving_path=\"Images\", show_logs=True, search_engines=[\"Google\", \"Bing\", \"DuckDuckGo\"]):\n",
    "    # Fonction pour afficher les logs seulement si show_logs est True\n",
    "    def log(message):\n",
    "        if show_logs:\n",
    "            print(message)\n",
    "\n",
    "    # Créer le dossier principal de base (Saving_Path) s'il n'existe pas\n",
    "    if not os.path.exists(saving_path):\n",
    "        os.makedirs(saving_path)\n",
    "\n",
    "    # Créer un sous-dossier pour cette recherche\n",
    "    target_folder = os.path.join(saving_path, folder_name)\n",
    "    if not os.path.exists(target_folder):\n",
    "        os.makedirs(target_folder)\n",
    "\n",
    "    # Compter combien d'images existent déjà dans le dossier\n",
    "    existing_images = len([name for name in os.listdir(target_folder) if os.path.isfile(os.path.join(target_folder, name))])\n",
    "\n",
    "    # Définir les URLs des moteurs de recherche selon les noms fournis\n",
    "    List_Urls = {\n",
    "        \"Google\": \"https://www.google.com/search?q=intitle:{query}&tbm=isch\",  # Option 1: ajout de 'intitle:'\n",
    "        \"Bing\": \"https://www.bing.com/images/search?q={query}&form=HDRSC2\",\n",
    "        \"DuckDuckGo\": \"https://duckduckgo.com/?q={query}&t=hb&iar=images&iax=images&ia=images\"  # Option 6: ajout de DuckDuckGo\n",
    "    }\n",
    "\n",
    "    # Filtrer les moteurs de recherche à utiliser\n",
    "    List_Urls = {name: url for name, url in List_Urls.items() if name in search_engines}\n",
    "\n",
    "    image_counter = existing_images  # Garde un compteur global pour éviter de remplacer les images\n",
    "\n",
    "    driver = setup_driver(allow_popups=allow_popups)  # Utiliser le nouveau driver configuré\n",
    "\n",
    "    for lang, lang_queries in queries.items():\n",
    "        mandatory_words = mandatory_keywords.get(lang, [])  # Obtenir les mots obligatoires pour la langue\n",
    "        for query in lang_queries:\n",
    "            for Moteur, Url in List_Urls.items():\n",
    "                log(f\"Récupération des images pour la requête: {query} depuis {Moteur}...\")\n",
    "                driver.get(Url.format(query=query))  # Remplacer {query} par la requête spécifique\n",
    "\n",
    "                # Faire défiler la page pour charger plus d'images (Option 5: augmenter le nombre de défilements)\n",
    "                for _ in range(10):  # Augmenté à 15 pour charger plus d'images\n",
    "                    driver.find_element(By.TAG_NAME, \"body\").send_keys(Keys.END)\n",
    "                    time.sleep(2)  # Pause pour laisser la page charger les nouvelles images\n",
    "\n",
    "                # Obtenir le HTML de la page après le défilement\n",
    "                soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "                # Récupérer toutes les balises <img>\n",
    "                img_tags = soup.find_all('img')\n",
    "\n",
    "                # Extraire les URLs des images\n",
    "                img_urls = []\n",
    "                for img in img_tags:\n",
    "                    img_url = img.get('src')\n",
    "                    alt_text = img.get('alt', '').lower()  # Récupérer le texte alternatif (utile pour la pertinence)\n",
    "                    title_text = img.get('title', '').lower()  # Récupérer le texte du titre (Option 7)\n",
    "\n",
    "                    # Filtrer pour s'assurer que les images contiennent les mots-clés obligatoires dans l'URL, alt-text, ou title-text\n",
    "                    if img_url and img_url.startswith('http'):\n",
    "                        if (any(keyword.lower() in img_url.lower() or keyword in alt_text or keyword in title_text for keyword in keywords)\n",
    "                            and all(m_word.lower() in title_text or m_word in alt_text for m_word in mandatory_words)):  # Option 7: mots obligatoires\n",
    "                            img_urls.append(img_url)\n",
    "\n",
    "                log(f\"URLs récupérées pour la requête '{query}': {len(img_urls)} images\")\n",
    "\n",
    "                # Télécharger et sauvegarder les images jusqu'à atteindre le nombre requis\n",
    "                downloaded_images = 0\n",
    "                for img_url in img_urls:\n",
    "                    if downloaded_images >= num_images:\n",
    "                        break  # Si on a atteint le nombre d'images requis, on arrête\n",
    "\n",
    "                    try:\n",
    "                        # Téléchargement de l'image\n",
    "                        log(f\"Tentative de téléchargement de l'image {downloaded_images + 1}/{num_images}: {img_url}\")\n",
    "                        img_response = requests.get(img_url)\n",
    "                        img = Image.open(BytesIO(img_response.content))\n",
    "\n",
    "                        # Déduire le format de l'image\n",
    "                        img_format = img.format.lower() if img.format else 'jpeg'\n",
    "                        img_extension = img_format if img_format != 'jpeg' else 'jpg'\n",
    "\n",
    "                        # Construire le chemin de sauvegarde avec un compteur dynamique global\n",
    "                        img_path = os.path.join(target_folder, f\"image_{image_counter}.{img_extension}\")\n",
    "                        img.save(img_path)\n",
    "\n",
    "                        log(f\"Image {image_counter + 1} sauvegardée sous {img_path}\")\n",
    "                        image_counter += 1  # Incrémenter le compteur d'images global\n",
    "                        downloaded_images += 1  # Incrémenter le nombre d'images téléchargées\n",
    "\n",
    "                    except Exception as e:\n",
    "                        log(f\"Erreur lors du téléchargement de l'image {image_counter + 1}: {e}\")\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "# # Utilisation de la fonction avec des requêtes organisées par langue\n",
    "# queries = {\n",
    "#     \"French\": [\n",
    "#         \"panneau+stop+images+reelles\",\n",
    "#     ],\n",
    "#     \"English\": [ \"Stop+sign+real+images\"\n",
    "#     ],\n",
    "#     \"Spanish\": [\n",
    "#         \"señal+de+pare+imágenes+reales\"\n",
    "#     ],\n",
    "#     \"German\": [\"stop+schild+echte+bilder\"]\n",
    "# }\n",
    "# # Mots obligatoires pour chaque langue\n",
    "# mandatory_keywords = {\n",
    "#     \"French\": [\"stop\"]\n",
    "# ,\n",
    "#     \"English\": [],\n",
    "#     \"Spanish\": [],\n",
    "#     \"German\": []\n",
    "# }\n",
    "\n",
    "# keywords = [\"panneau\", \"stop\", \"pare\", \"schild\"]  # Mots-clés pour filtrer les images\n",
    "# Allow_Popups = False\n",
    "# Saving_Path = \"Images\"  # Chemin de base où les dossiers seront créés\n",
    "# Folder_Name = \"Stop_Signs\"  # Nom du dossier pour cette recherche\n",
    "# Show_Logs = True  # Activer ou désactiver les logs\n",
    "# Search_Engines = [\"Google\", \"Bing\", \"DuckDuckGo\", \"Yahoo\"]\n",
    "#                     # Liste des moteurs de recherche à utiliser\n",
    "\n",
    "# # Appel de la fonction avec l'option de pop-ups désactivée, le dossier spécifié, et les logs activés\n",
    "# scrape_images_with_selenium(queries, num_images=50, folder_name=Folder_Name, keywords=keywords, mandatory_keywords=mandatory_keywords, allow_popups=Allow_Popups, saving_path=Saving_Path, show_logs=Show_Logs, search_engines=Search_Engines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "def load_sign_data(json_file):\n",
    "    with open(json_file, \"r\", encoding=\"utf-8\") as file:\n",
    "        sign_data = json.load(file)\n",
    "    return sign_data\n",
    "\n",
    "def scrape_sign_images(json_file, num_images=50, allow_popups=False, saving_path=\"Images\", show_logs=True, search_engines=[\"Google\", \"Bing\", \"DuckDuckGo\"]):\n",
    "\n",
    "    # Create Saving Path if it doesn't exist\n",
    "    if not os.path.exists(saving_path):\n",
    "        os.makedirs(saving_path)\n",
    "\n",
    "\n",
    "    # Fonction pour afficher les logs seulement si show_logs est True\n",
    "    def log(message):\n",
    "        if show_logs:\n",
    "            print(message)\n",
    "\n",
    "    # Charger les données des panneaux depuis le fichier JSON\n",
    "    sign_data = load_sign_data(json_file)\n",
    "\n",
    "    # Préparer la structure des requêtes\n",
    "    queries = {}\n",
    "    mandatory_keywords = {}\n",
    "\n",
    "    # Pour chaque catégorie de panneaux, extraire les traductions dans chaque langue\n",
    "    for category, signs in sign_data.items():\n",
    "        # Créer le dossier selon la catégorie de panneau\n",
    "        category_folder = os.path.join(saving_path, category)\n",
    "        if not os.path.exists(category_folder):\n",
    "            os.makedirs(category_folder)\n",
    "\n",
    "        for sign, translations in signs.items():  # Itérer sur les panneaux\n",
    "            # Créer un sous-dossier pour chaque panneau\n",
    "            sign_folder = os.path.join(category_folder, sign)  # Créer le dossier du panneau\n",
    "            if not os.path.exists(sign_folder):\n",
    "                os.makedirs(sign_folder)\n",
    "\n",
    "            for lang, translation_data in translations.items():\n",
    "                # Ajouter les requêtes pour chaque langue\n",
    "                if lang not in queries:\n",
    "                    queries[lang] = []\n",
    "                queries[lang].append(translation_data['Requête'])\n",
    "\n",
    "                # Ajouter les mots obligatoires (s'il y en a)\n",
    "                if lang not in mandatory_keywords:\n",
    "                    mandatory_keywords[lang] = []\n",
    "                # mandatory_keywords[lang].extend()\n",
    "\n",
    "            # Utiliser le code de scraping existant pour chaque langue et chaque moteur de recherche\n",
    "            scrape_images_with_selenium(queries, num_images=num_images, folder_name=sign_folder, keywords=[\"panneau\" , \"sign\", \"senal\", \"schild\"] , mandatory_keywords=mandatory_keywords, allow_popups=allow_popups, saving_path=sign_folder, show_logs=show_logs, search_engines=search_engines)\n",
    "\n",
    "    log(\"Scraping terminé et les images sont triées dans les dossiers correspondants.\")\n",
    "\n",
    "# Exemple d'utilisation avec un fichier JSON\n",
    "json_file = \"data.json\"  # Remplace par le nom de ton fichier JSON\n",
    "scrape_sign_images(json_file, num_images=50, saving_path=\"Images\", show_logs=True, search_engines=[\"Google\", \"Bing\", \"DuckDuckGo\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Personal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
